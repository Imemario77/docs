---
title: Non-streaming chat
subtitle: Build reliable chat integrations with complete response patterns for batch processing and simple UIs
---

## Overview

Build a chat integration that receives complete responses after processing, perfect for batch processing, simple UIs, or when you need the full response before proceeding. Ideal for integrations where real-time display isn't essential.

**What You'll Build:**
* Simple request-response chat patterns with immediate complete responses
* Session-based conversations that maintain context across multiple chats
* Batch processing capabilities for handling multiple conversations
* Error-resistant integration with predictable response timing

**Use Cases:**
* FAQ systems and knowledge bases
* Batch processing of customer inquiries
* Simple chat widgets without typing indicators
* Backend integrations where full responses are required

## Prerequisites

* Completed [Chat quickstart](/docs/chat/quickstart) tutorial
* Understanding of basic HTTP requests and JSON handling
* Familiarity with JavaScript promises or async/await

## Scenario

We'll build a comprehensive help desk system for "TechFlow" that processes support tickets through text chat, maintains conversation history, and integrates with their existing ticketing system that requires complete responses.

---

## 1. Basic Non-Streaming Implementation

<Steps>
  <Step title="Create a simple chat function">
    Start with a basic non-streaming chat implementation:
    
    ```bash title="Basic Non-Streaming Request"
    curl -X POST https://api.vapi.ai/chat \
      -H "Authorization: Bearer YOUR_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{
        "assistantId": "your-assistant-id",
        "input": "I need help resetting my password"
      }'
    ```
  </Step>
  <Step title="Understand the response structure">
    Non-streaming responses come back as complete JSON objects:
    
    ```json title="Complete Chat Response"
    {
      "id": "chat_123456",
      "orgId": "org_789012",
      "assistantId": "assistant_345678",
      "name": "Password Reset Help",
      "sessionId": "session_901234",
      "messages": [
        {
          "role": "user",
          "content": "I need help resetting my password"
        }
      ],
      "output": [
        {
          "role": "assistant",
          "content": "I can help you reset your password. First, let me verify your account information..."
        }
      ],
      "createdAt": "2024-01-15T09:30:00Z",
      "updatedAt": "2024-01-15T09:30:01Z"
    }
    ```
  </Step>
  <Step title="Implement in JavaScript">
    Create a reusable function for non-streaming chat:
    
    ```javascript title="non-streaming-chat.js"
    async function sendChatMessage(message, previousChatId = null) {
      const response = await fetch('https://api.vapi.ai/chat', {
        method: 'POST',
        headers: {
          'Authorization': 'Bearer YOUR_API_KEY',
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          assistantId: 'your-assistant-id',
          input: message,
          ...(previousChatId && { previousChatId })
        })
      });

      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`);
      }

      const chat = await response.json();
      return {
        chatId: chat.id,
        response: chat.output[0].content,
        fullData: chat
      };
    }
    ```
  </Step>
</Steps>

---

## 2. Implement Context Management with Sessions

<Steps>
  <Step title="Create a session for persistent context">
    Sessions allow multiple chats to share the same conversation context:
    
    ```bash title="Create Session"
    curl -X POST https://api.vapi.ai/session \
      -H "Authorization: Bearer YOUR_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{
        "assistantId": "your-assistant-id"
      }'
    ```
  </Step>
  <Step title="Use the session across multiple chats">
    Once you have a session ID, use it for related conversations:
    
    ```bash title="First Message with Session"
    curl -X POST https://api.vapi.ai/chat \
      -H "Authorization: Bearer YOUR_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{
        "sessionId": "session_abc123",
        "input": "My account is locked and I can't access the dashboard"
      }'
    ```
    
    ```bash title="Follow-up in Same Session"
    curl -X POST https://api.vapi.ai/chat \
      -H "Authorization: Bearer YOUR_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{
        "sessionId": "session_abc123",
        "input": "I tried the suggestions but still can't get in"
      }'
    ```
  </Step>
  <Step title="Implement session management in JavaScript">
    Build a session-aware chat manager:
    
    ```javascript title="session-manager.js"
    class ChatSessionManager {
      constructor(apiKey, assistantId) {
        this.apiKey = apiKey;
        this.assistantId = assistantId;
        this.sessions = new Map();
      }

      async createSession(sessionName = 'default') {
        const response = await fetch('https://api.vapi.ai/session', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${this.apiKey}`,
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            assistantId: this.assistantId
          })
        });

        const session = await response.json();
        this.sessions.set(sessionName, session.id);
        return session.id;
      }

      async sendMessage(message, sessionName = 'default') {
        let sessionId = this.sessions.get(sessionName);
        
        if (!sessionId) {
          sessionId = await this.createSession(sessionName);
        }

        const response = await fetch('https://api.vapi.ai/chat', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${this.apiKey}`,
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            sessionId: sessionId,
            input: message
          })
        });

        const chat = await response.json();
        return {
          response: chat.output[0].content,
          chatId: chat.id,
          sessionId: sessionId
        };
      }
    }

    // Usage example
    const chatManager = new ChatSessionManager('YOUR_API_KEY', 'your-assistant-id');
    
    const response1 = await chatManager.sendMessage("I need help with billing", "customer_123");
    console.log(response1.response);
    
    const response2 = await chatManager.sendMessage("Can you explain the charges?", "customer_123");
    console.log(response2.response); // Will remember the billing context
    ```
  </Step>
</Steps>

---

## 3. Build a Ticket Processing System

<Steps>
  <Step title="Create a help desk integration">
    Build a system that processes support tickets using non-streaming chat:
    
    ```javascript title="help-desk-processor.js"
    class HelpDeskProcessor {
      constructor(apiKey, assistantId) {
        this.apiKey = apiKey;
        this.assistantId = assistantId;
        this.tickets = new Map();
      }

      async processTicket(ticketId, userMessage, priority = 'normal') {
        try {
          // Check if this ticket has previous context
          const previousChatId = this.tickets.get(ticketId);
          
          const response = await fetch('https://api.vapi.ai/chat', {
            method: 'POST',
            headers: {
              'Authorization': `Bearer ${this.apiKey}`,
              'Content-Type': 'application/json'
            },
            body: JSON.stringify({
              assistantId: this.assistantId,
              input: userMessage,
              ...(previousChatId && { previousChatId })
            })
          });

          if (!response.ok) {
            throw new Error(`Chat API error: ${response.status}`);
          }

          const chat = await response.json();
          
          // Store chat ID for future context
          this.tickets.set(ticketId, chat.id);
          
          return {
            ticketId,
            chatId: chat.id,
            userMessage,
            assistantResponse: chat.output[0].content,
            timestamp: new Date().toISOString(),
            priority,
            status: 'processed'
          };
          
        } catch (error) {
          console.error(`Error processing ticket ${ticketId}:`, error);
          return {
            ticketId,
            userMessage,
            error: error.message,
            timestamp: new Date().toISOString(),
            priority,
            status: 'failed'
          };
        }
      }

      async batchProcessTickets(tickets) {
        const results = [];
        
        for (const ticket of tickets) {
          const result = await this.processTicket(
            ticket.id, 
            ticket.message, 
            ticket.priority
          );
          results.push(result);
          
          // Add delay to avoid rate limiting
          await new Promise(resolve => setTimeout(resolve, 100));
        }
        
        return results;
      }
    }
    ```
  </Step>
  <Step title="Test the ticket processing system">
    Try processing multiple tickets with context:
    
    ```javascript title="test-help-desk.js"
    const processor = new HelpDeskProcessor('YOUR_API_KEY', 'your-assistant-id');

    // Process individual tickets
    const ticket1 = await processor.processTicket(
      'TICKET-001',
      'My login isn\'t working after the recent update',
      'high'
    );
    console.log('Ticket 1 response:', ticket1.assistantResponse);

    // Follow-up on the same ticket (maintains context)
    const ticket1_followup = await processor.processTicket(
      'TICKET-001',
      'I tried clearing cache but still have the same issue',
      'high'
    );
    console.log('Follow-up response:', ticket1_followup.assistantResponse);

    // Batch process multiple tickets
    const batchTickets = [
      { id: 'TICKET-002', message: 'How do I export my data?', priority: 'normal' },
      { id: 'TICKET-003', message: 'Billing question about my subscription', priority: 'normal' },
      { id: 'TICKET-004', message: 'App crashes when uploading files', priority: 'high' }
    ];

    const batchResults = await processor.batchProcessTickets(batchTickets);
    console.log('Batch processing results:', batchResults);
    ```
  </Step>
</Steps>

---

## 4. Implement Custom Assistant Configurations

<Steps>
  <Step title="Use inline assistant configuration">
    Instead of pre-created assistants, define configuration per request:
    
    ```bash title="Custom Assistant Request"
    curl -X POST https://api.vapi.ai/chat \
      -H "Authorization: Bearer YOUR_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{
        "input": "I need help with enterprise features",
        "assistant": {
          "model": {
            "provider": "openai",
            "model": "gpt-4",
            "temperature": 0.7,
            "messages": [
              {
                "role": "system",
                "content": "You are a specialized TechFlow enterprise support agent. Focus on enterprise features, security, and compliance questions. Always ask for the customer's enterprise tier before providing specific feature information."
              }
            ]
          },
          "voice": {
            "provider": "azure",
            "voiceId": "andrew"
          }
        }
      }'
    ```
  </Step>
  <Step title="Create specialized chat handlers">
    Build different chat handlers for different types of requests:
    
    ```javascript title="specialized-handlers.js"
    class SpecializedChatHandlers {
      constructor(apiKey) {
        this.apiKey = apiKey;
      }

      async handleTechnicalSupport(userMessage, previousChatId = null) {
        return this.sendWithAssistant(userMessage, {
          model: {
            provider: 'openai',
            model: 'gpt-4',
            temperature: 0.3, // Lower temperature for technical accuracy
            messages: [{
              role: 'system',
              content: `You are a technical support specialist for TechFlow. 
              
              Guidelines:
              - Ask clarifying questions to diagnose issues
              - Provide step-by-step troubleshooting
              - Escalate complex issues to human engineers
              - Always ask about error messages, browser/OS, and steps to reproduce`
            }]
          }
        }, previousChatId);
      }

      async handleBillingSupport(userMessage, previousChatId = null) {
        return this.sendWithAssistant(userMessage, {
          model: {
            provider: 'openai',
            model: 'gpt-4',
            temperature: 0.2, // Very low temperature for billing accuracy
            messages: [{
              role: 'system',
              content: `You are a billing support specialist for TechFlow.
              
              Guidelines:
              - Be precise about billing terms and dates
              - Always verify account information before discussing charges
              - Escalate refund requests to human agents
              - Provide clear explanations of charges and billing cycles`
            }]
          }
        }, previousChatId);
      }

      async handleGeneralInquiry(userMessage, previousChatId = null) {
        return this.sendWithAssistant(userMessage, {
          model: {
            provider: 'openai',
            model: 'gpt-4',
            temperature: 0.7, // Higher temperature for friendly conversation
            messages: [{
              role: 'system',
              content: `You are a friendly customer service representative for TechFlow.
              
              Guidelines:
              - Be helpful and conversational
              - Route technical issues to technical support
              - Route billing questions to billing support
              - Provide general information about features and plans`
            }]
          }
        }, previousChatId);
      }

      async sendWithAssistant(message, assistantConfig, previousChatId = null) {
        const response = await fetch('https://api.vapi.ai/chat', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${this.apiKey}`,
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            input: message,
            assistant: assistantConfig,
            ...(previousChatId && { previousChatId })
          })
        });

        const chat = await response.json();
        return {
          chatId: chat.id,
          response: chat.output[0].content,
          type: this.getRequestType(assistantConfig)
        };
      }

      getRequestType(config) {
        const systemMessage = config.model.messages[0].content.toLowerCase();
        if (systemMessage.includes('technical')) return 'technical';
        if (systemMessage.includes('billing')) return 'billing';
        return 'general';
      }
    }
    ```
  </Step>
  <Step title="Test specialized handlers">
    Test each specialized handler type:
    
    ```javascript title="test-specialized.js"
    const handlers = new SpecializedChatHandlers('YOUR_API_KEY');

    // Test technical support
    const techResponse = await handlers.handleTechnicalSupport(
      "My API requests are returning 500 errors intermittently"
    );
    console.log('Technical support:', techResponse.response);

    // Test billing support
    const billingResponse = await handlers.handleBillingSupport(
      "I was charged twice this month, can you help?"
    );
    console.log('Billing support:', billingResponse.response);

    // Test general inquiry
    const generalResponse = await handlers.handleGeneralInquiry(
      "What features are included in the Pro plan?"
    );
    console.log('General inquiry:', generalResponse.response);
    ```
  </Step>
</Steps>

---

## 5. Test and Validate Your Implementation

<Steps>
  <Step title="Test conversation continuity">
    Verify that context is maintained across multiple messages:
    
    ```bash title="Context Test Series"
    # First message
    curl -X POST https://api.vapi.ai/chat \
      -H "Authorization: Bearer YOUR_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{
        "assistantId": "your-assistant-id",
        "input": "I need help with API integration"
      }'
    
    # Follow-up (should remember API context)
    curl -X POST https://api.vapi.ai/chat \
      -H "Authorization: Bearer YOUR_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{
        "assistantId": "your-assistant-id",
        "previousChatId": "chat_from_first_response",
        "input": "What authentication methods do you support?"
      }'
      
    # Third message (should remember both previous messages)
    curl -X POST https://api.vapi.ai/chat \
      -H "Authorization: Bearer YOUR_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{
        "assistantId": "your-assistant-id",
        "previousChatId": "chat_from_second_response",
        "input": "Can you provide example code for OAuth setup?"
      }'
    ```
  </Step>
  <Step title="Test error handling">
    Verify your system handles errors gracefully:
    
    ```bash title="Error Scenarios"
    # Test with invalid assistant ID
    curl -X POST https://api.vapi.ai/chat \
      -H "Authorization: Bearer YOUR_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{
        "assistantId": "invalid-assistant-id",
        "input": "This should fail gracefully"
      }'
      
    # Test with missing input
    curl -X POST https://api.vapi.ai/chat \
      -H "Authorization: Bearer YOUR_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{
        "assistantId": "your-assistant-id"
      }'
    ```
  </Step>
  <Step title="Performance test with batch processing">
    Test handling multiple requests efficiently:
    
    ```javascript title="performance-test.js"
    async function performanceTest() {
      const processor = new HelpDeskProcessor('YOUR_API_KEY', 'your-assistant-id');
      
      const startTime = Date.now();
      const testTickets = Array.from({ length: 10 }, (_, i) => ({
        id: `PERF-TEST-${i + 1}`,
        message: `Test message ${i + 1}: How do I troubleshoot connection issues?`,
        priority: i % 2 === 0 ? 'high' : 'normal'
      }));
      
      const results = await processor.batchProcessTickets(testTickets);
      const endTime = Date.now();
      
      console.log(`Processed ${results.length} tickets in ${endTime - startTime}ms`);
      console.log(`Average time per ticket: ${(endTime - startTime) / results.length}ms`);
      console.log(`Success rate: ${results.filter(r => r.status === 'processed').length}/${results.length}`);
    }
    
    performanceTest();
    ```
  </Step>
</Steps>

## What You've Built

Congratulations! You now have:

✅ **Reliable non-streaming chat integration** with predictable response timing  
✅ **Session-based context management** for maintaining long conversations  
✅ **Batch processing capabilities** for handling multiple tickets efficiently  
✅ **Specialized assistant configurations** for different types of support  
✅ **Error-resistant architecture** with proper validation and handling  
✅ **Performance-tested system** ready for production load  

## When to Use Non-Streaming

* **Batch processing** - When you need to process multiple requests sequentially
* **Simple UIs** - When real-time typing indicators aren't required  
* **Complete responses required** - When you need the full response before proceeding
* **Backend integrations** - When feeding responses into other systems
* **FAQ and knowledge systems** - Where instant complete answers are preferred

## Next Steps

Enhance your non-streaming chat system further:

* **[Add streaming capabilities](/docs/chat/streaming)** - Upgrade to real-time responses for better UX
* **[OpenAI compatibility](/docs/chat/openai-compatibility)** - Use familiar OpenAI SDK patterns  
* **[Integrate tools](/docs/tools/custom-tools)** - Enable your assistant to call external APIs and databases
* **[Add voice capabilities](/docs/calls/call-outbound)** - Extend your text chat to voice interactions

<Callout>
Need help? Chat with the team on our [Discord](https://discord.com/invite/pUFNcf2WmH) or mention us on [X/Twitter](https://x.com/Vapi_AI).
</Callout>
