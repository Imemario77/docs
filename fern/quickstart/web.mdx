---
title: Web SDK Quickstart
subtitle: Learn to build web applications with Vapi Web SDK in under 5 minutes.
slug: quickstart/web
---

## Installation

<Steps>
  <Step title="Install the package">
    <CodeBlocks>
      <CodeBlock title="npm">
        ```bash
        npm install @vapi-ai/web
        ```
      </CodeBlock>
      <CodeBlock title="yarn">
        ```bash
        yarn add @vapi-ai/web
        ```
      </CodeBlock>
      <CodeBlock title="pnpm">
        ```bash
        pnpm add @vapi-ai/web
        ```
      </CodeBlock>
      <CodeBlock title="bun">
        ```bash
        bun add @vapi-ai/web
        ```
      </CodeBlock>
    </CodeBlocks>
  </Step>

  <Step title="Get your credentials">
    You'll need your public API key and/or private API key from the [Dashboard → Vapi API Keys](https://dashboard.vapi.ai/org/api-keys).

    <Warning>
      Always use your **public key** (starts with `pk_`) in client-side code. Never expose your private key in the browser.
    </Warning>
  </Step>

  <Step title="Get your assistant ID">
    You'll need your assistant ID from the [Dashboard → Assistants](https://dashboard.vapi.ai/assistants).
  </Step>
</Steps>

## Quick Start

<Tabs>
  <Tab title="Next.js">
    <Steps>
      <Step title="Environment setup">
        ```env title=".env.local"
        NEXT_PUBLIC_VAPI_API_KEY=pk_your_public_key_here
        NEXT_PUBLIC_VAPI_ASSISTANT_ID=your_assistant_id_here
        ```
      </Step>

      <Step title="Create voice component">
        ```typescript title="components/voice-button.tsx"
        'use client';

        import Vapi from '@vapi-ai/web';
        import { useState } from 'react';

        export function VoiceButton() {
          const [vapi] = useState(() => new Vapi(process.env.NEXT_PUBLIC_VAPI_API_KEY!));
          const [isActive, setIsActive] = useState(false);

          const toggleCall = async () => {
            if (isActive) {
              vapi.stop();
            } else {
              await vapi.start(process.env.NEXT_PUBLIC_VAPI_ASSISTANT_ID!);
            }
          };

          vapi.on('call-start', () => setIsActive(true));
          vapi.on('call-end', () => setIsActive(false));

          return (
            <button 
              onClick={toggleCall} 
              className="px-4 py-2 bg-blue-500 text-white rounded hover:bg-blue-600"
            >
              {isActive ? 'End Call' : 'Start Call'}
            </button>
          );
        }
        ```
      </Step>

      <Step title="Use in your page">
        ```typescript title="app/page.tsx"
        import { VoiceButton } from '@/components/voice-button';

        export default function Home() {
          return (
            <main className="p-8">
              <h1 className="text-2xl font-bold mb-4">Voice AI Demo</h1>
              <VoiceButton />
            </main>
          );
        }
        ```
      </Step>
    </Steps>
  </Tab>

  <Tab title="React + Vite">
    <Steps>
      <Step title="Environment setup">
        ```env title=".env"
        VITE_VAPI_API_KEY=pk_your_public_key_here
        VITE_VAPI_ASSISTANT_ID=your_assistant_id_here
        ```
      </Step>

      <Step title="Create voice component">
        ```typescript title="components/VoiceButton.tsx"
        import Vapi from '@vapi-ai/web';
        import { useState } from 'react';

        export function VoiceButton() {
          const [vapi] = useState(() => new Vapi(import.meta.env.VITE_VAPI_API_KEY));
          const [isActive, setIsActive] = useState(false);

          const toggleCall = async () => {
            if (isActive) {
              vapi.stop();
            } else {
              await vapi.start(import.meta.env.VITE_VAPI_ASSISTANT_ID);
            }
          };

          vapi.on('call-start', () => setIsActive(true));
          vapi.on('call-end', () => setIsActive(false));

          return (
            <button 
              onClick={toggleCall}
              className="px-4 py-2 bg-blue-500 text-white rounded hover:bg-blue-600"
            >
              {isActive ? 'End Call' : 'Start Call'}
            </button>
          );
        }
        ```
      </Step>

      <Step title="Use in App">
        ```typescript title="src/App.tsx"
        import { VoiceButton } from './components/VoiceButton';

        function App() {
          return (
            <div className="p-8">
              <h1 className="text-2xl font-bold mb-4">Voice AI Demo</h1>
              <VoiceButton />
            </div>
          );
        }

        export default App;
        ```
      </Step>
    </Steps>
  </Tab>

  <Tab title="Vanilla JS">
    ```javascript title="main.js"
    import Vapi from '@vapi-ai/web';

    const vapi = new Vapi('pk_your_public_key_here');
    const button = document.getElementById('voice-btn');
    let isActive = false;

    button.addEventListener('click', async () => {
      if (isActive) {
        vapi.stop();
      } else {
        await vapi.start('your_assistant_id');
      }
    });

    vapi.on('call-start', () => {
      isActive = true;
      button.textContent = 'End Call';
    });

    vapi.on('call-end', () => {
      isActive = false;
      button.textContent = 'Start Call';
    });
    ```
  </Tab>
</Tabs>

## Core Features

### Starting and Stopping Calls

Start voice conversations with your AI assistant using either a pre-configured assistant ID or inline configuration. You can customize the model, voice, and behavior on-the-fly.

```typescript
import Vapi from "@vapi-ai/web";
import { CreateAssistantDTO } from "@vapi-ai/web/dist/api";

// Initialize Vapi
const vapi = new Vapi('pk_your_public_key');

// Start a call with assistant ID
await vapi.start('your_assistant_id');

// Start with inline assistant config
const assistantConfig: CreateAssistantDTO = {
  model: {
    provider: "openai",
    model: "gpt-4o-2024-05-13",
    messages: [
      {
        role: "system",
        content: "You are a helpful assistant."
      }
    ]
  },
  voice: {
    provider: "11labs",
    voiceId: "21m00Tcm4TlvDq8ikWAM",
  },
  firstMessage: "Hello! How can I help you today?",
};
await vapi.start(assistantConfig);

// End a call
vapi.stop();
```

### Event Handling

Monitor call lifecycle, speech activity, and real-time transcription. These events help you build responsive UIs and handle call state changes.

```typescript
// Call lifecycle events
vapi.on('call-start', () => {
  console.log('Call started');
});

vapi.on('call-end', () => {
  console.log('Call ended');
});

// Speech events
vapi.on('speech-start', () => {
  console.log('User started speaking');
});

vapi.on('speech-end', () => {
  console.log('User stopped speaking');
});

// Message events
vapi.on('message', (message) => {
  console.log('Received message:', message);
});

// Volume level (for visualizations)
vapi.on('volume-level', (level) => {
  console.log('Volume level:', level);
});

// Error handling
vapi.on('error', (error) => {
  console.error('Call error:', error);
});
```

### Sending Messages

Inject context or trigger actions by sending messages to your assistant during an active call. Useful for providing real-time updates or user interface interactions.

```typescript
// Send a text message
vapi.send({
  type: 'add-message',
  message: {
    role: 'system',
    content: 'The user just clicked a button on the interface.'
  }
});

// Add tool call result
vapi.send({
  type: 'add-message',
  message: {
    role: 'tool',
    content: {
      name: 'getUserData',
      parameters: { userId: '123' },
    }
  }
});
```

### Mute Control

Control microphone input during calls. Essential for privacy and managing when the assistant should listen to user speech.

```typescript
// Mute/unmute the microphone
vapi.setMuted(true);  // Mute
vapi.setMuted(false); // Unmute

// Check if muted
const isMuted = vapi.isMuted();
```

### Assistant Overrides

Customize assistant behavior for specific calls without modifying your base assistant configuration in Vapi API or Vapi Dashboard. Override transcription settings, recording options, conversation flow, etc.

```typescript
const vapi = new Vapi('pk_your_key');

const overrides: OverrideAssistantDTO = {
  // Assistant overrides
  firstMessageMode: 'assistant-waits-for-user', // wait for user to speak first
  recordingEnabled: false, // don't record the call
  
  // use deepgram for transcription
  transcriber: {
    provider: 'deepgram',
    model: 'nova-2',
    language: 'en-US'
  }, 

  // use custom summary prompt
  analysisPlan: {
    summaryPrompt: 'Summarize the conversation in a few sentences.',
  },
};

// Start call with overrides
await vapi.start('your_assistant_id', overrides);
```

### React Hook Example

Simplify Vapi integration with a custom React hook that manages call state, conversation history, and common controls in a reusable way.

```typescript title="hooks/useVapi.ts"
import { useState, useEffect, useCallback } from 'react';
import Vapi from '@vapi-ai/web';

export function useVapi(apiKey: string) {
  const [vapi] = useState(() => new Vapi(apiKey));
  const [isActive, setIsActive] = useState(false);
  const [isMuted, setIsMuted] = useState(false);
  const [volume, setVolume] = useState(0);
  const [conversation, setConversation] = useState<Array<{
    role: 'user' | 'assistant';
    text: string;
    timestamp: string;
  }>>([]);

  useEffect(() => {
    vapi.on('call-start', () => setIsActive(true));
    vapi.on('call-end', () => setIsActive(false));
    vapi.on('volume-level', setVolume);
    
    vapi.on('message', (message) => {
      if (message.type === 'transcript' && message.transcript) {
        setConversation(prev => [...prev, {
          role: message.transcript.role,
          text: message.transcript.text,
          timestamp: new Date().toISOString(),
        }]);
      }
    });

    return () => {
      vapi.removeAllListeners();
    };
  }, [vapi]);

  const start = useCallback(async (assistantId: string) => {
    setConversation([]);
    await vapi.start(assistantId);
  }, [vapi]);

  const stop = useCallback(() => {
    vapi.stop();
  }, [vapi]);

  const toggleMute = useCallback(() => {
    const newMuted = !isMuted;
    vapi.setMuted(newMuted);
    setIsMuted(newMuted);
  }, [vapi, isMuted]);

  return {
    vapi,
    isActive,
    isMuted,
    volume,
    conversation,
    start,
    stop,
    toggleMute
  };
}
```

### Defining Custom Tools

Enable your assistant to call external functions and APIs with custom tools.

```typescript
// Assistant with function calling
const assistantWithTools: CreateAssistantDTO = {
  model: {
    provider: "openai",
    model: "gpt-4o-2024-05-13",
    tools: [
      {
        type: "function",
        function: {
          name: "get_weather",
          description: "Get current weather for a location",
          parameters: {
            type: "object",
            properties: {
              location: {
                type: "string",
                description: "City name"
              }
            },
            required: ["location"]
          }
        }
      }
    ],
  },
  voice: {
    provider: "11labs",
    voiceId: "21m00Tcm4TlvDq8ikWAM",
  },
  serverUrl: "https://your-domain.com/api/webhook",
  firstMessage: "Hello! I can help you with weather information and more.",
};

await vapi.start(assistantWithTools);
```

### Video Recording

Capture video recordings of web-based voice calls. 

```typescript
// Assistant with video recording enabled
const videoAssistant = {
  model: {
    provider: "openai",
    model: "gpt-4o-2024-11-20",
  },
  voice: {
    provider: "11labs",
    voiceId: "21m00Tcm4TlvDq8ikWAM",
  },
  artifactPlan: {
    videoRecordingEnabled: true,
    recordingEnabled: true,
  },
  firstMessage: "Hello! This call is being recorded with video. How can I help?",
};

await vapi.start(videoAssistant);
```

## Next Steps

<CardGroup cols={2}>
  <Card title="SDK Reference" icon="code" href="/sdk/web">
    Complete Web SDK documentation
  </Card>
  <Card title="API Reference" icon="book-open" href="/api-reference">
    Complete API reference documentation
  </Card>
</CardGroup>

<Info>
  **Need help?** Join our [Discord community](https://discord.gg/vapi) or check out the [full documentation](/overview).
</Info>
